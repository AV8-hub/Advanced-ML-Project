{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1f0fb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import random\n",
    "import cv2\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.transforms import v2\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec963dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterDataset(folder, classes=None, mode='train'):    \n",
    "    # initialize COCO api for instance annotations\n",
    "    annFile = '{}/annotations/instances_{}2017.json'.format(folder, mode)\n",
    "    coco = COCO(annFile)\n",
    "    \n",
    "    images = []\n",
    "    if classes!=None:\n",
    "        # iterate for each individual class in the list\n",
    "        for className in classes:\n",
    "            # get all images containing given categories\n",
    "            catIds = coco.getCatIds(catNms=className)\n",
    "            imgIds = coco.getImgIds(catIds=catIds)\n",
    "            images += coco.loadImgs(imgIds)\n",
    "    \n",
    "    else:\n",
    "        imgIds = coco.getImgIds()\n",
    "        images = coco.loadImgs(imgIds)\n",
    "    \n",
    "    # Now, filter out the repeated images\n",
    "    unique_images = []\n",
    "    for i in range(len(images)):\n",
    "        if images[i] not in unique_images:\n",
    "            \n",
    "            unique_images.append(images[i])\n",
    "            \n",
    "    random.shuffle(unique_images)\n",
    "    dataset_size = len(unique_images)\n",
    "    \n",
    "    return unique_images, dataset_size, coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2899116d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=22.31s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "folder = './COCOdataset2017'\n",
    "classes = ['sports ball']\n",
    "mode = 'train'\n",
    "\n",
    "images, dataset_size, coco = filterDataset(folder, classes,  mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3126620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassName(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return None\n",
    "\n",
    "def getImage(imageObj, img_folder, input_image_size):\n",
    "    # Read and normalize an image\n",
    "    train_img = io.imread(img_folder + '/' + imageObj['file_name'])/255.0\n",
    "    # Resize\n",
    "    train_img = cv2.resize(train_img, input_image_size)\n",
    "    if (len(train_img.shape)==3 and train_img.shape[2]==3): # If it is a RGB 3 channel image\n",
    "        return train_img\n",
    "    else: # To handle a black and white image, increase dimensions to 3\n",
    "        stacked_img = np.stack((train_img,)*3, axis=-1)\n",
    "        return stacked_img\n",
    "    \n",
    "def getMask(imageObj, classes, coco, catIds, input_image_size):\n",
    "    annIds = coco.getAnnIds(imageObj['id'], catIds=catIds, iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    cats = coco.loadCats(catIds)\n",
    "    train_mask = np.zeros(input_image_size)\n",
    "    for a in range(len(anns)):\n",
    "        className = getClassName(anns[a]['category_id'], cats)\n",
    "        pixel_value = classes.index(className)+1\n",
    "        new_mask = cv2.resize(coco.annToMask(anns[a])*pixel_value, input_image_size)\n",
    "        train_mask = np.maximum(new_mask, train_mask)\n",
    "\n",
    "    # Add extra dimension for parity with train_img size [X * X * 3]\n",
    "    train_mask = train_mask.reshape(input_image_size[0], input_image_size[1], 1)\n",
    "    return train_mask  \n",
    "\n",
    "\n",
    "def getTensors(images, classes, coco, folder, mode, input_image_size=(224,224)):\n",
    "    \n",
    "    img_folder = '{}/images/{}'.format(folder, mode)\n",
    "    dataset_size = len(images)\n",
    "    catIds = coco.getCatIds(catNms=classes)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(dataset_size):\n",
    "        imageObj = images[i]\n",
    "            \n",
    "        ### Retrieve Image ###\n",
    "        img = getImage(imageObj, img_folder, input_image_size)\n",
    "        X.append(img)\n",
    "\n",
    "        ### Create Mask ###\n",
    "        mask = getMask(imageObj, classes, coco, catIds, input_image_size)\n",
    "        y.append(mask)\n",
    "        \n",
    "    X = torch.Tensor(X)\n",
    "    y = torch.Tensor(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def AugmentData(X, y, p = 0.5):\n",
    "\n",
    "    n = len(X)\n",
    "    for i in range(n):\n",
    "        image = X[i]\n",
    "        mask = y[i]\n",
    "\n",
    "        for k in range(3):\n",
    "            if random.random() < p:\n",
    "                image = TF.hflip(image)\n",
    "                mask = TF.hflip(mask)\n",
    "            \n",
    "            if random.random() < p:\n",
    "                image = TF.vflip(image)\n",
    "                mask = TF.vflip(mask)\n",
    "            \n",
    "            if random.random() < p:\n",
    "                image = TF.vflip(image)\n",
    "                mask = TF.vflip(mask)\n",
    "            \n",
    "            if random.random() < p:\n",
    "                i, j, h, w = v2.RandomResizedCrop(size=(224, 224)).get_params(image, scale=[0.08, 1.0], ratio = [0.75, 1.3333333333333333])\n",
    "                image = TF.crop(image, i, j, h, w)\n",
    "                mask = TF.crop(mask, i, j, h, w)\n",
    "            \n",
    "            if random.random() < p:\n",
    "                image = v2.ColorJitter(brightness=random.random())(image)\n",
    "\n",
    "            if random.random() < p:\n",
    "                noise = torch.randn(image.size())*0.3 + 0.5\n",
    "                image = image + noise\n",
    "                image = v2.ColorJitter(brightness=random.random())(image)\n",
    "            \n",
    "            X = torch.cat((X,image),0)\n",
    "            y = torch.cat((y,mask),0)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def getDataloader(X, y, batch_size = 64):\n",
    "\n",
    "    dataset = TensorDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size = batch_size)\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad6321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "getDataloader(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
